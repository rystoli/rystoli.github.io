<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP <--- Ryan thinks they're awesome
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Ryan M Stolier | New York University</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<link rel="stylesheet" href="assets/ai/css/academicons.css"/>
		<link rel="icon" type="image/png" href="images/favicon.png" sizes="32x32">

	</head>
	<body>

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>
					<h1 id="logo">Ryan M. Stolier</h1>
					
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about" class="active">About</a></li>
						<li><a href="#rymvpa">RyMVPA</a></li>
						<li><a href="#blog">"Blog"</a></li>
					</ul>
				</nav>
				<footer>
					<ul class="icons">
					<li><font size="6"><a href="CV-Stolier_9_18_17.pdf">CV</a></font></li>
					<li><a href="https://scholar.google.com/citations?user=nDW764QAAAAJ&hl=en" class="ai ai-google-scholar-square ai-2x"></a></li>
						<li><a href="https://twitter.com/rystoli" class="icon fa-twitter fa-2x"><span class="label">Twitter</span></a></li>
						<li><a href="https://github.com/rystoli/RyMVPA" class="icon fa-github fa-2x"><span class="label">Github</span></a></li>
						<li><a href="mailto:rystoli@nyu.edu" class="icon fa-envelope fa-2x"><span class="label">Email</span></a></li>
					</ul>
				</footer>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

<!-- about -->
							<section id="about">
								<div class="container">

										<h2>Ryan M Stolier</h2>
										<h4>New York University</h4><br>
<a href="CV-Stolier_9_18_17.pdf">curriculum vitae</a> 
<hr>
									<p>Ryan Stolier is a doctoral student in the Department of Psychology at New York University, where he works primarily with Dr. Jonathan Freeman. His research bridges methods of psychology and neuroscience to study how we categorize and form personality impressions of others (e.g., race, competence). His work focuses primarily on how cognitive and neural systems integrate bottom-up cues (e.g., facial cues) and top-down social factors (e.g., stereotypes) to form these perceptions. 

<br><br>He also amateur codes research tools (e.g., RyMVPA, below). He also leads a double life as a folk musician, world traveler, and scifi/anime enthusiast.

<h5>See resources below and the side menu for more information. As well, visit the <a href="http://psych.nyu.edu/freemanlab/index.htm"><u>Freeman Lab site</u></a>.</h5></p>
									
									<h4>Selected publications:</h4>
									Stolier, R.M. & Freeman, J.B. (2016). <a href="http://psych.nyu.edu/freemanlab/pubs/2016_Stolier&Freeman.pdf">Neural pattern similarity reveals the <br>inherent intersection of social categories</a>. <i>Nature Neuroscience</i>.<br><br>
									Stolier, R.M. & Freeman, J.B. (2017). <a href="http://psych.nyu.edu/freemanlab/pubs/2017_StolierFreeman_JNeuro.pdf">A neural mechanism of social <br>categorization</a>. <i>Journal of Neuroscience</i>.<br><br>
									<h4>Selected media coverage:</h4>

<a href="https://www.washingtonpost.com/news/speaking-of-science/wp/2016/05/02/scientists-show-how-we-start-stereotyping-the-moment-we-see-a-face/">Scientists Show How We Start Stereotyping the Moment We See a Face</a><br>
<i>Washington Post</i>, May 2, 2016 <br><br>

<a href="https://www.facebook.com/jfreemanlab/videos/1640920019463267">Through the Wormhole with Morgan Freeman, Season Premiere: 'Are We all Bigots?'</a><br>
<i>Science Channel</i>, April 29, 2015 

									<hr><h3>Research</h3>


In our research, we hope to further outline the intricacies of how we form perceptions of others, with focus on categorizations (e.g., race) and trait impressions (e.g., competence) from faces. We see social perception as an integrative process, where top-down factors (e.g., stereotypes) may structure the way we perceive and represent others' social category memberships (e.g., race) and personality traits (e.g., trustworthiness). Importantly, our work bridges behavioral, neuroimaging, and computational methods to develop comprehensive ideas about both the structure and dynamics of these processes.

<br><br><h4>Social categorizations</h4>

How do we come to categorize others' race, gender, or age? In recent work, we found social categories that share stereotypes are perceived more similarly. For instance, male and black faces share 'dominance' trait stereotypes, and thereby facilitate perception of one another and share neural representations (Stolier & Freeman, 2016 - <i>Nature Neuroscience</i>; Brooks, Stolier, & Freeman, in press - <i>Social Cognition</i>). This work highlights an important, counter-intuitive route through which trait stereotypes can be activated during perception, where categories perceived from face (e.g., male) elicit activation of other categories not perceived (e.g., black) and consequently stereotypes and evaluations relevant to the other category (for instance, <a href="https://www8.gsb.columbia.edu/newsroom/newsn/2214/gender-and-race-how-overlapping-stereotypes-affect-interracial-dating-leadership-selection-and-athletic-participation">see work on behavioral consequences of this process by Galinsky, Hall, & Cuddy, 2013 — <i>Psychological Science</i></a>).

<br><br><h4>Trait impressions</h4>

In ongoing research, we find trait impressions based on others' facial appearance are structured by social knowledge. For instance, our internal beliefs about how personality traits covary in the world (are trustworthy people typically assertive?) may underlie how quick inferences from a face (how nice someone appears) may cascade into myriad personality impression (e.g., trustworthiness, extroversion, assertiveness, intelligence, creativity; <a href="./blog/9_8_17.html">work in progress, see demonstration here</a>). This has important implications for how we understand other people, especially as we may make consequential personality impressions (e.g., trustworthiness) about others based on what little we know about them (e.g., sociability). Furthermore, these trait associations (e.g., how trustworthy an intelligent person is perceived) may shift in certain contexts (e.g., become more negatively related towards females, negative attitudes towards competent females prominent in the United States; Glick & Fiske, 1996 — <i>JPSP</i>).

<br><br><h4>Integrative neural networks</h4>

Across these many questions, my work combines behavioral, neuroimaging, and computational methods to build a coherent picture of these processes (Stolier & Freeman, 2016 - <i>Psychological Inquiry</i>). Our work has begun to elucidate how 'initial' social perceptions in visual brain regions are actually influenced by many higher-order processes, from stereotypes (via the orbitofrontal cortex; Stolier & Freeman, 2016 - <i>Nature Neuroscience</i>) to cognitive control (via the dorsal anterior cingulate; Stolier & Freeman, 2017 - <i>Journal of Neuroscience</i>). Future work hopes to extend computational accounts of social categorization (Freeman & Ambady, 2011 — <i>Psychological Review</i>) to develop a fuller picture of trait impression formations. These approaches play a crucial role in our work, both constraining and informing our theoretical perspectives.

<p><h5>Please see the side menu for more information. As well, visit the <a href="http://psych.nyu.edu/freemanlab/index.htm"><u>Freeman Lab site</u></a>.</h5></p>

								</div>
							</section>


<!-- rymvpa -->
							<section id="rymvpa">
								<div class="container">
									<h3>RyMVPA</h3>
									<h4>What? Why? </h4>

<a href="https://github.com/rystoli/RyMVPA">RyMVPA</a> is an unnecessarily eponymous wrapper for <a href="http://www.pymvpa.org/">PyMVPA</a>. PyMVPA is a wonderful module for MVPA, multi-variate pattern analysis, of data - especially, in my case, fMRI data. In RyMVPA, many of PyMVPA's pattern analysis tools are available in single function commands to make the magic of PyMVPA less verbose. For instance, you can run an entire searchlight multiple regression Representational Similarity Analysis with a little this:<br><br>
<code>slRSA_m_nSs( data, target_DM, [control_DM_1 ... control_DM_k] )</code><br><br>
It also comes with many additional methods and tools you may find useful. <br><br>

<i class="icon fa-check-square-o"></i>   Perform basic MVPA Classification and RSA analyses in single lines of code (within ROIs, searchlights, for single or all subjects)
<br>
<i class="icon fa-check-square-o"></i>   Perform RSA in a multiple regression (controlling for and including additional models), only assessing certain similarity values (of the DM), or compare similarities of specific condition-pairs directly
<br>
<i class="icon fa-check-square-o"></i>   See if between-subject individual differences or trial-by-trial covariates relate to the neural similarity of certain conditions
<br>
<i class="icon fa-check-square-o"></i>   Train your classifier on certain targets, and test on others
<br><br><b>To install</b>, see instructions at the <a href="https://github.com/rystoli/RyMVPA#installation">RyMVPA github home</a>.
<br><br>
See an initial <b>tutorial</b> from my "blog" below and <a href="blog/9_18_17.html">here</a>.

								</div>
							</section>

<!-- blog -->
							<section id="blog">
								<div class="container">
								<h3>"Blog"</h3>
<ul>
						<li><a href="blog/1_25_17.html">Data science shlacktivism compendium</a></li>
						<li><a href="blog/2_10_17.html">Cluster threshold corrections in PyMVPA with GroupClusterThreshold(), via Stelzer et al. 2013: NN clustering method</a></li>
						<li><a href="blog/2_27_17.html">Cluster threshold corrections in PyMVPA with GroupClusterThreshold(), via Stelzer et al. 2013: manual entry of cluster sizes</li>
						<li><a href="blog/3_10_17.html">Face stimulus and tool collection</a></li>
						<li><a href="blog/3_10_17b.html">Facegen SDK .FG file feature export to CSV</a></li>
						<li><a href="blog/9_8_17.html">Face trait judgment variance modeling in python (Jupyter notebook)</a></li>
						<li><a href="blog/9_18_17.html">RyMVPA Tutorial Part I - introduction (Jupyter notebook)</a></li> 
						<li><a href="blog/9_25_17.html">RyMVPA - Concise intro to PyMVPA with notes. See there doc for better details (Jupyter notebook)</a></li> 
						<li><a href="blog/9_27_17.html">Easy PyMVPA Installation (for Mac and Windows)</a></li> 
					</ul>
								</div>
							</section>
							
							<!-- End -->
							<section><div class="container">
							<a href="#one">Back to top</a>
							</div></section>
							
					</div>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>&copy; Ryan M Stolier. All rights reserved?</li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollzer.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
